{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/header.png\" alt=\"Logo UCLM-ESII\" align=\"right\">\n",
    "\n",
    "<br><br><br><br>\n",
    "<h2><font color=\"#92002A\" size=4>Trabajo Fin de Grado</font></h2>\n",
    "\n",
    "<h1><font color=\"#6B001F\" size=5>Generación automática de playlist de canciones <br> mediante técnicas de minería de datos</font></h1>\n",
    "<h2><font color=\"#92002A\" size=3>Parte 12 - Resultados</font></h2>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "    <font color=\"#B20033\" size=3><strong>Autor</strong>: <em>Miguel Ángel Cantero Víllora</em></font><br>\n",
    "    <br>\n",
    "    <font color=\"#B20033\" size=3><strong>Directores</strong>: <em>José Antonio Gámez Martín</em></font><br>\n",
    "    <font color=\"#B20033\" size=3><em>Juan Ángel Aledo Sánchez</em></font><br>\n",
    "    <br>\n",
    "<font color=\"#B20033\" size=3>Grado en Ingeniería Informática</font><br>\n",
    "<font color=\"#B20033\" size=2>Escuela Superior de Ingeniería Informática | Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#92002A\" size=5>Índice</font></h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Definicion de funciones auxiliares](#section2)\n",
    "* [3. Resultados](#section3)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite establecer la anchura de la celda\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pythonenv\\mcidaen\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from lightfm import LightFM\n",
    "from tqdm.notebook import tqdm as tqdm_nb\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "NUM_THREADS = 8\n",
    "SEED = 0\n",
    "\n",
    "# Directorio empleado para guardar/leer los datos generados\n",
    "DATA_PATH = 'MPD_CSV'\n",
    "TEST_DATA_PATH = 'MPD_TEST'\n",
    "MODELS_PATH = \"models\"\n",
    "BACKUP_PATH = 'backup'\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_PATH,'lightfm_model.pkl')\n",
    "MPD_LFM_FILE = os.path.join(DATA_PATH, \"mpd_lightfm.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MPD_LFM_FILE, \"rb\") as read_file:\n",
    "    mpd_lfm_dict = pickle.load(read_file)\n",
    "    \n",
    "tfg_model = joblib.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pythonenv\\mcidaen\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_tracks = pd.read_csv(os.path.join(DATA_PATH,'mpd.tracks.csv'))\n",
    "df_plstrs = pd.read_csv(os.path.join(DATA_PATH,'mpd.pls-tracks.csv'), index_col=0)\n",
    "\n",
    "# Creamos un diccionario para traducir los id de Spotify\n",
    "# a nuestro identificador PID\n",
    "tracks_ids = df_tracks.track_id.to_list()\n",
    "tracks_translate_dict = dict()\n",
    "for track_pid, track_id in enumerate(tracks_ids):\n",
    "    tracks_translate_dict[track_id] = track_pid   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#92002A\">1 - Introducción</font>\n",
    "<br>\n",
    "\n",
    "Por último, vamos a emplear el conjunto de 10.000 playlists cuyo contenido esta incompleto, y han sido agrupadas en 10 categorías de 1.000 listas, para ver el rendimiento de nuestro modelo ante resultados desconocidos.\n",
    "\n",
    "En el caso de las métricas de los resultados, volvemos a emplear la precisión cuando k es igual a 10, 20, 50 y 100.\n",
    "\n",
    "<br>\n",
    "\n",
    "Antes de ver los resultados obtenidos, vamos a recordar qué categorías tenemos en el conjunto de prueba empleado:\n",
    "\n",
    "1.\tPredicción de pistas para una playlist dado sólo su título.\n",
    "2.\tPredicción de pistas para una playlist dado su título y la primera pista.\n",
    "3.\tPredicción de pistas para una playlist dado su título y las primeras 5 pistas.\n",
    "4.\tPredicción de pistas para una playlist dadas las primeras 5 pistas (sin título).\n",
    "5.\tPredicción de pistas para una playlist dado su título y las primeras 10 pistas.\n",
    "6.\tPredicción de pistas para una playlist dadas las primeras 10 pistas (sin título).\n",
    "7.\tPredicción de pistas para una playlist dado su título y las primeras 25 pistas.\n",
    "8.\tPredicción de pistas para una playlist dado su título y 25 pistas aleatorias.\n",
    "9.\tPredicción de pistas para una playlist dado su título y las primeras 100 pistas.\n",
    "10.\tPredicción de pistas para una playlist dado su título y 100 pistas aleatorias.\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#92002A\">2 - Definicion de funciones auxiliares</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula las métricas para una playlists\n",
    "def plstrs_rec_analysis(rec_items, val_items):\n",
    "    \"\"\"\n",
    "    :param rec_items: Items que ha recomendado el modelo.\n",
    "    :param val_items: Items del conjunto de validación.\n",
    "    :return: Diccionario con las métricas.\n",
    "    \"\"\"\n",
    "    val_set = set(val_items)\n",
    "    rec10_set = set(rec_items[:10])\n",
    "    rec20_set = set(rec_items[:20])\n",
    "    rec50_set = set(rec_items[:50])\n",
    "    rec100_set = set(rec_items[:100])\n",
    "    \n",
    "    analysis_results = dict()\n",
    "    \n",
    "    analysis_results['top_10'] = {'common' : rec10_set.intersection(val_set),\n",
    "                                  'score' : len(rec10_set.intersection(val_set))/len(val_set)}\n",
    "    analysis_results['top_20'] = {'common' : rec20_set.intersection(val_set),\n",
    "                                  'score' : len(rec20_set.intersection(val_set))/len(val_set)}\n",
    "    analysis_results['top_50'] = {'common' : rec50_set.intersection(val_set),\n",
    "                                  'score' : len(rec50_set.intersection(val_set))/len(val_set)}\n",
    "    analysis_results['top_100'] = {'common' : rec100_set.intersection(val_set),\n",
    "                                   'score' : len(rec100_set.intersection(val_set))/len(val_set)}\n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza la predicción para una playlists del conjunto de prueba\n",
    "def make_test_prediction(model, data, pls_pids, u_features=None, N=10):\n",
    "    \"\"\"\n",
    "    :param model: Modelo a emplear.\n",
    "    :param data: Matriz de interacciones (Sparse Matrix).\n",
    "    :param pls_pids: Usuarios de los que se desea obtener recomendaciones.\n",
    "    :param labels : Etiquetas/nombres de los items\n",
    "    :param N: (Opcional) Número de items a predecir similares, por defecto se devuelven 10.\n",
    "    :return: Lista de diccionarios.\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "\n",
    "    #Numero de usuarios e items de la matriz\n",
    "    n_pls, n_items = data.shape\n",
    "\n",
    "    #Genera recomendación para cada usuario\n",
    "    for pl_id in tqdm_nb(pls_pids):\n",
    "        \n",
    "        #Items que el usuario conoce\n",
    "        known_positives = data.tocsr()[pl_id].indices\n",
    "        \n",
    "        #Items que nuestro modelo predice al usuario\n",
    "        scores = model.predict(pl_id, np.arange(n_items), user_features=u_features, num_threads=NUM_THREADS)\n",
    "        #Ordena los items por puntuación\n",
    "        top_items = np.argsort(-scores)\n",
    "\n",
    "        # Borramos los items conocidos de las recomendaciones\n",
    "        sorter = np.argsort(top_items)\n",
    "        removable_indices = sorter[np.searchsorted(top_items, known_positives, sorter=sorter)]\n",
    "        top_items = np.delete(top_items,removable_indices)\n",
    "\n",
    "        # Resultados\n",
    "        result_dict = {'pl_pid': pl_id,\n",
    "                       'known_items' : list(known_positives),\n",
    "                       'recommended_items' : list(top_items[:N])}\n",
    "        \n",
    "        results_list.append(result_dict)\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_metrics(rec_pls, val_pls, n_categories, num_pls_category):\n",
    "    results_dict = dict()\n",
    "    start_pid = 0\n",
    "    end_pid = num_pls_category\n",
    "    \n",
    "    \n",
    "    for i in range(0,n_categories):\n",
    "        res_category = []\n",
    "        for j in range(start_pid,end_pid):\n",
    "            res_category.append(plstrs_rec_analysis(rec_pls[j]['recommended_items'],\n",
    "                                                    val_pls[j]['validation_tracks']))\n",
    "            \n",
    "        results_dict[f\"Category_{i+1}\"] = res_category\n",
    "        \n",
    "        start_pid += num_pls_category\n",
    "        end_pid += num_pls_category\n",
    "        \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#92002A\">3 - Resultados</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_file = os.path.join(BACKUP_PATH,'pls_test_predictions.pkl')\n",
    "\n",
    "if os.path.isfile(predictions_file):\n",
    "    with open(predictions_file, \"rb\") as read_file:\n",
    "        test_set_predictions = pickle.load(read_file)\n",
    "else:\n",
    "    test_set_predictions = make_test_prediction(tfg_model, mpd_lfm_dict['plstrs_interactions'], \n",
    "                                                range(1000000,1010000),\n",
    "                                                u_features=mpd_lfm_dict['pls_features'], N=500)\n",
    "    with open(predictions_file, \"wb\") as write_file:\n",
    "        pickle.dump(test_set_predictions, write_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = os.path.join(BACKUP_PATH,'pls_test_results.pkl')\n",
    "\n",
    "if os.path.isfile(results_file):\n",
    "    with open(results_file, \"rb\") as read_file:\n",
    "        test_set_results = pickle.load(read_file)\n",
    "else:\n",
    "    # Leemos el fichero JSON comprimido con las soluciones\n",
    "    mpd_test_results_file = os.path.join(TEST_DATA_PATH,'mpd.test_complete.zip')\n",
    "    with ZipFile(mpd_test_results_file,'r') as zip_file:\n",
    "        with zip_file.open(zip_file.namelist()[0]) as json_file:\n",
    "            data = json_file.read()\n",
    "            data = json.loads(data.decode())\n",
    "    \n",
    "    test_set_results = []\n",
    "    for pl in tqdm_nb(data['playlists']):\n",
    "        r = dict()\n",
    "        r['pid'] = pl['pid']\n",
    "        r['name'] = pl['name']\n",
    "        tracks_list = []\n",
    "        for track in pl['tracks']:\n",
    "            tr_id = track['track_uri'].split(':')[-1]        \n",
    "            tracks_list.append(tracks_translate_dict[tr_id])\n",
    "        known_tracks = df_plstrs[df_plstrs.index == pl['pid']].track_pid.to_list()\n",
    "        for track in known_tracks : tracks_list.remove(track)\n",
    "        r['known_tracks'] = known_tracks\n",
    "        r['validation_tracks'] = tracks_list\n",
    "        test_set_results.append(r)\n",
    "        \n",
    "    with open(results_file, \"wb\") as write_file:\n",
    "        pickle.dump(test_set_results, write_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_category_metrics(test_set_predictions, test_set_results, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "list_results = []\n",
    "for pos in range(9000,10000):\n",
    "    ret = set(test_set_predictions[pos]['recommended_items'][:k])\n",
    "    rel = set(test_set_results[pos]['validation_tracks'])\n",
    "    result = len(ret.intersection(rel))/min(len(ret),len(rel))\n",
    "    list_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category_1\n",
      "------------\n",
      "precision@10:\t 0.01154549907255993\n",
      "precision@20:\t 0.02021793233261168\n",
      "precision@50:\t 0.039427970885525285\n",
      "precision@100:\t 0.06130557730607572\n",
      "\n",
      "Category_2\n",
      "------------\n",
      "precision@10:\t 0.025071236604546417\n",
      "precision@20:\t 0.042084862463926155\n",
      "precision@50:\t 0.08015292991214694\n",
      "precision@100:\t 0.11921548263613857\n",
      "\n",
      "Category_3\n",
      "------------\n",
      "precision@10:\t 0.03796103436348459\n",
      "precision@20:\t 0.06140177505199794\n",
      "precision@50:\t 0.11480495012300322\n",
      "precision@100:\t 0.17381157943718004\n",
      "\n",
      "Category_4\n",
      "------------\n",
      "precision@10:\t 0.03655898939747491\n",
      "precision@20:\t 0.062245915208051825\n",
      "precision@50:\t 0.11617549449005804\n",
      "precision@100:\t 0.17463617582472074\n",
      "\n",
      "Category_5\n",
      "------------\n",
      "precision@10:\t 0.04099674446246121\n",
      "precision@20:\t 0.06771235437878595\n",
      "precision@50:\t 0.13185734919031733\n",
      "precision@100:\t 0.19636569688854563\n",
      "\n",
      "Category_6\n",
      "------------\n",
      "precision@10:\t 0.037361537865082485\n",
      "precision@20:\t 0.06778326820048224\n",
      "precision@50:\t 0.12828542922755803\n",
      "precision@100:\t 0.18908126391685098\n",
      "\n",
      "Category_7\n",
      "------------\n",
      "precision@10:\t 0.04288702223654908\n",
      "precision@20:\t 0.0720972540537811\n",
      "precision@50:\t 0.13664691522705386\n",
      "precision@100:\t 0.2064036828898092\n",
      "\n",
      "Category_8\n",
      "------------\n",
      "precision@10:\t 0.06197781418303673\n",
      "precision@20:\t 0.1039690094535425\n",
      "precision@50:\t 0.18633389987545265\n",
      "precision@100:\t 0.26982602770148356\n",
      "\n",
      "Category_9\n",
      "------------\n",
      "precision@10:\t 0.027283888790548418\n",
      "precision@20:\t 0.04660438232753723\n",
      "precision@50:\t 0.09590569172313018\n",
      "precision@100:\t 0.15704045329325042\n",
      "\n",
      "Category_10\n",
      "------------\n",
      "precision@10:\t 0.0585474837312901\n",
      "precision@20:\t 0.09476123631910319\n",
      "precision@50:\t 0.17240711950308188\n",
      "precision@100:\t 0.2570949903644574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category in results.items():\n",
    "    for category_key in category:\n",
    "        print(category_key)\n",
    "        print('-' * 12)\n",
    "        \n",
    "        top_10_scores = []\n",
    "        top_20_scores = []\n",
    "        top_50_scores = []\n",
    "        top_100_scores = []\n",
    "        \n",
    "        for r in results[category_key]:\n",
    "            top_10_scores.append(r['top_10']['score'])\n",
    "            top_20_scores.append(r['top_20']['score'])\n",
    "            top_50_scores.append(r['top_50']['score'])\n",
    "            top_100_scores.append(r['top_100']['score'])\n",
    "            \n",
    "        print('precision@10:\\t',sum(top_10_scores)/1000)\n",
    "        print('precision@20:\\t',sum(top_20_scores)/1000)\n",
    "        print('precision@50:\\t',sum(top_50_scores)/1000)\n",
    "        print('precision@100:\\t',sum(top_100_scores)/1000)\n",
    "        \n",
    "        break\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver en la tabla anterior, comparando los casos donde se ofrece el mismo número de pistas con título y sin el, categorías 3, 4, 5 y 6, vemos que los resultados de nuestro modelo mejoran sensiblemente si se tiene en cuenta el título.\n",
    "\n",
    "En las categorías 7, 8, 9 y 10, nuestro modelo es capaz de ofrecer mejores recomendaciones en los casos que se le proporcionan pistas de posiciones aleatorias. Esto se debe a que, en numerosas playlists, las pistas que contienen están agrupadas por artista. Al obtener pistas de esta forma, se proporciona un número de artistas mayor que si recomendásemos las primeras *n* posiciones. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-graduation-cap\" aria-hidden=\"true\" style=\"color:#92002A\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
